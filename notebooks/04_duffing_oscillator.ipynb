{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Neural Network Prediction of Duffing Oscillator Dynamics\n",
    "\n",
    "**Team 19**: Vlad-Flavius Misăilă, Robert-Daniel Man, Sebastian-Adrian Mărginean\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Duffing oscillator is a forced nonlinear oscillator that can exhibit both periodic and chaotic behavior:\n",
    "\n",
    "$$\n",
    "\\frac{d^2x}{dt^2} + \\delta\\frac{dx}{dt} + \\alpha x + \\beta x^3 = \\gamma\\cos(\\omega t)\n",
    "$$\n",
    "\n",
    "As a first-order system:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dx}{dt} &= y \\\\\n",
    "\\frac{dy}{dt} &= -\\delta y - \\alpha x - \\beta x^3 + \\gamma\\cos(\\omega t)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Standard parameters**: $\\alpha = -1.0$, $\\beta = 1.0$, $\\delta = 0.3$, $\\gamma = 0.37$, $\\omega = 1.2$\n",
    "\n",
    "**Objective**: Train neural networks to predict future states in the chaotic regime. This system demonstrates transition from periodic to chaotic behavior depending on forcing amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path to import src modules\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "\n",
    "# Import our custom modules\n",
    "from src.dynamical_systems import DuffingOscillator\n",
    "from src.data_preparation import generate_trajectory, create_sequences\n",
    "from src.neural_models import FeedForwardPredictor, LSTMPredictor, GRUPredictor, NeuralPredictor\n",
    "from src.evaluation import (\n",
    "    evaluate_prediction, plot_trajectory_3d, plot_time_series,\n",
    "    plot_prediction_error, plot_training_history, prediction_horizon_analysis\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"✓ Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Generate Duffing Oscillator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Duffing oscillator in chaotic regime\n",
    "duffing = DuffingOscillator(alpha=-1.0, beta=1.0, delta=0.3, gamma=0.37, omega=1.2)\n",
    "\n",
    "# Generate trajectory\n",
    "print(\"Generating Duffing oscillator trajectory...\")\n",
    "initial_state = np.array([0.1, 0.1])\n",
    "t, trajectory = generate_trajectory(\n",
    "    duffing,\n",
    "    initial_state=initial_state,\n",
    "    t_span=(0, 100),  # 100 time units\n",
    "    dt=0.01,          # Small time step for accuracy\n",
    "    noise_std=0.0     # No noise initially\n",
    ")\n",
    "\n",
    "print(f\"✓ Generated {len(t)} time points\")\n",
    "print(f\"✓ Trajectory shape: {trajectory.shape}\")\n",
    "print(f\"✓ Time range: [{t[0]:.2f}, {t[-1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Visualize the Duffing Phase Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D phase space visualization (Duffing is a 2D forced system)\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Phase portrait\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(trajectory[:, 0], trajectory[:, 1], 'b-', alpha=0.6, linewidth=0.5)\n",
    "ax1.set_xlabel('x (Position)', fontsize=11)\n",
    "ax1.set_ylabel('y (Velocity)', fontsize=11)\n",
    "ax1.set_title('Duffing Attractor (Chaotic Regime)', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(0, color='k', linewidth=0.5)\n",
    "ax1.axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Phase portrait (skip transient)\n",
    "ax2 = fig.add_subplot(122)\n",
    "skip_transient = 5000\n",
    "ax2.plot(trajectory[skip_transient:, 0], trajectory[skip_transient:, 1], 'b-', alpha=0.6, linewidth=0.5)\n",
    "ax2.set_xlabel('x (Position)', fontsize=11)\n",
    "ax2.set_ylabel('y (Velocity)', fontsize=11)\n",
    "ax2.set_title('Strange Attractor (After Transient)', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(0, color='k', linewidth=0.5)\n",
    "ax2.axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series visualization\n",
    "plot_time_series(\n",
    "    t[:2000],  # Plot first 2000 points for clarity\n",
    "    trajectory[:2000],\n",
    "    feature_names=['x (Position)', 'y (Velocity)'],\n",
    "    title='Duffing Oscillator Time Series (Chaotic)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Prepare Training Data\n",
    "\n",
    "We use a sliding window approach:\n",
    "- **Input**: Past `window_size` states\n",
    "- **Output**: Next state (1 step ahead)\n",
    "- **Split**: 80% training, 20% testing (sequential split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "WINDOW_SIZE = 50\n",
    "PREDICTION_HORIZON = 1\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Create sequences\n",
    "print(\"Preparing training data...\")\n",
    "X_train, y_train, X_test, y_test, scaler = create_sequences(\n",
    "    trajectory,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    prediction_horizon=PREDICTION_HORIZON,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    normalize=True,\n",
    "    normalization_method='standard'\n",
    ")\n",
    "\n",
    "print(f\"✓ Training set: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"✓ Testing set: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"✓ Input features per sample: {WINDOW_SIZE * 2} (window={WINDOW_SIZE} × dims=2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Train Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feed-Forward model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Feed-Forward Neural Network\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fnn_model = FeedForwardPredictor(\n",
    "    input_dim=WINDOW_SIZE * 2,  # Flatten window\n",
    "    hidden_dims=[128, 64, 32],  # Three hidden layers\n",
    "    output_dim=2,                # Predict 2D state\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "fnn_predictor = NeuralPredictor(fnn_model, learning_rate=0.001)\n",
    "\n",
    "# Train model\n",
    "fnn_history = fnn_predictor.train(\n",
    "    X_train, y_train,\n",
    "    X_val=X_test, y_val=y_test,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(fnn_history, title='Feed-Forward Network Training History')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Train LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training LSTM Network\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lstm_model = LSTMPredictor(\n",
    "    input_dim=2,          # 2D state at each time step\n",
    "    hidden_dim=64,        # LSTM hidden dimension\n",
    "    num_layers=2,         # 2 LSTM layers\n",
    "    output_dim=2,         # Predict 2D state\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "lstm_predictor = NeuralPredictor(lstm_model, learning_rate=0.001)\n",
    "\n",
    "# Train model\n",
    "lstm_history = lstm_predictor.train(\n",
    "    X_train, y_train,\n",
    "    X_val=X_test, y_val=y_test,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(lstm_history, title='LSTM Network Training History')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Evaluate Models: One-Step Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "fnn_predictions = fnn_predictor.predict(X_test)\n",
    "lstm_predictions = lstm_predictor.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "fnn_metrics = evaluate_prediction(y_test, fnn_predictions)\n",
    "lstm_metrics = evaluate_prediction(y_test, lstm_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ONE-STEP PREDICTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFeed-Forward Network:\")\n",
    "print(f\"  RMSE:  {fnn_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:   {fnn_metrics['mae']:.6f}\")\n",
    "print(f\"  NRMSE: {fnn_metrics['nrmse']:.6f}\")\n",
    "\n",
    "print(\"\\nLSTM Network:\")\n",
    "print(f\"  RMSE:  {lstm_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:   {lstm_metrics['mae']:.6f}\")\n",
    "print(f\"  NRMSE: {lstm_metrics['nrmse']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform to original scale\n",
    "y_test_original = scaler.inverse_transform(y_test)\n",
    "fnn_pred_original = scaler.inverse_transform(fnn_predictions)\n",
    "lstm_pred_original = scaler.inverse_transform(lstm_predictions)\n",
    "\n",
    "# Plot phase space predictions for a subset\n",
    "n_plot = 500\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Feed-Forward predictions\n",
    "axes[0].plot(y_test_original[:n_plot, 0], y_test_original[:n_plot, 1], \n",
    "             'b-', linewidth=2, alpha=0.5, label='True')\n",
    "axes[0].plot(fnn_pred_original[:n_plot, 0], fnn_pred_original[:n_plot, 1], \n",
    "             'r--', linewidth=1.5, alpha=0.7, label='FNN Prediction')\n",
    "axes[0].set_xlabel('x (Position)', fontsize=11)\n",
    "axes[0].set_ylabel('y (Velocity)', fontsize=11)\n",
    "axes[0].set_title('Feed-Forward Network: True vs Predicted (One-Step)', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# LSTM predictions\n",
    "axes[1].plot(y_test_original[:n_plot, 0], y_test_original[:n_plot, 1], \n",
    "             'b-', linewidth=2, alpha=0.5, label='True')\n",
    "axes[1].plot(lstm_pred_original[:n_plot, 0], lstm_pred_original[:n_plot, 1], \n",
    "             'r--', linewidth=1.5, alpha=0.7, label='LSTM Prediction')\n",
    "axes[1].set_xlabel('x (Position)', fontsize=11)\n",
    "axes[1].set_ylabel('y (Velocity)', fontsize=11)\n",
    "axes[1].set_title('LSTM Network: True vs Predicted (One-Step)', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. Multi-Step Iterative Prediction\n",
    "\n",
    "Test how well the models can predict multiple steps into the future by using their own predictions as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an initial window from test set\n",
    "test_idx = 0\n",
    "initial_window = X_test[test_idx]\n",
    "n_future_steps = 200\n",
    "\n",
    "# True future trajectory\n",
    "true_future = y_test[test_idx:test_idx + n_future_steps]\n",
    "\n",
    "# Make iterative predictions\n",
    "print(f\"Making {n_future_steps}-step iterative predictions...\")\n",
    "fnn_future = fnn_predictor.iterative_predict(initial_window, n_future_steps)\n",
    "lstm_future = lstm_predictor.iterative_predict(initial_window, n_future_steps)\n",
    "\n",
    "print(\"✓ Predictions complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform\n",
    "true_future_orig = scaler.inverse_transform(true_future)\n",
    "fnn_future_orig = scaler.inverse_transform(fnn_future)\n",
    "lstm_future_orig = scaler.inverse_transform(lstm_future)\n",
    "\n",
    "# Visualize multi-step predictions in phase space\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# True trajectory\n",
    "axes[0].plot(true_future_orig[:, 0], true_future_orig[:, 1], 'b-', linewidth=1.5, alpha=0.7)\n",
    "axes[0].set_xlabel('x (Position)', fontsize=11)\n",
    "axes[0].set_ylabel('y (Velocity)', fontsize=11)\n",
    "axes[0].set_title('True Trajectory', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(0, color='k', linewidth=0.5)\n",
    "axes[0].axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# FNN prediction\n",
    "axes[1].plot(fnn_future_orig[:, 0], fnn_future_orig[:, 1], 'r-', linewidth=1.5, alpha=0.7)\n",
    "axes[1].set_xlabel('x (Position)', fontsize=11)\n",
    "axes[1].set_ylabel('y (Velocity)', fontsize=11)\n",
    "axes[1].set_title(f'Feed-Forward: {n_future_steps}-Step Iterative Prediction', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(0, color='k', linewidth=0.5)\n",
    "axes[1].axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# LSTM prediction\n",
    "axes[2].plot(lstm_future_orig[:, 0], lstm_future_orig[:, 1], 'g-', linewidth=1.5, alpha=0.7)\n",
    "axes[2].set_xlabel('x (Position)', fontsize=11)\n",
    "axes[2].set_ylabel('y (Velocity)', fontsize=11)\n",
    "axes[2].set_title(f'LSTM: {n_future_steps}-Step Iterative Prediction', fontsize=12)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].axhline(0, color='k', linewidth=0.5)\n",
    "axes[2].axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 10. Prediction Horizon Analysis\n",
    "\n",
    "Analyze how prediction error grows with prediction horizon (characteristic of chaotic systems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction horizon\n",
    "fnn_errors, steps = prediction_horizon_analysis(\n",
    "    fnn_predictor, initial_window, true_future, max_steps=n_future_steps\n",
    ")\n",
    "\n",
    "lstm_errors, _ = prediction_horizon_analysis(\n",
    "    lstm_predictor, initial_window, true_future, max_steps=n_future_steps\n",
    ")\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(steps, fnn_errors, 'b-', linewidth=2, label='Feed-Forward', alpha=0.7)\n",
    "ax.plot(steps, lstm_errors, 'r-', linewidth=2, label='LSTM', alpha=0.7)\n",
    "ax.set_xlabel('Prediction Horizon (steps)', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_title('Prediction Error Growth (Duffing Oscillator - Chaotic)', fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 11. Sensitivity to Noise\n",
    "\n",
    "Test model robustness by adding noise to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy trajectory\n",
    "print(\"Testing with noisy data...\")\n",
    "noise_levels = [0.0, 0.01, 0.05, 0.1]\n",
    "noise_results = {'fnn': [], 'lstm': []}\n",
    "\n",
    "for noise_std in noise_levels:\n",
    "    print(f\"\\nNoise level: {noise_std}\")\n",
    "    \n",
    "    # Generate noisy trajectory\n",
    "    _, noisy_traj = generate_trajectory(\n",
    "        duffing, initial_state, t_span=(0, 100), dt=0.01, noise_std=noise_std\n",
    "    )\n",
    "    \n",
    "    # Prepare data\n",
    "    X_tr, y_tr, X_te, y_te, _ = create_sequences(\n",
    "        noisy_traj, WINDOW_SIZE, PREDICTION_HORIZON, TRAIN_RATIO, normalize=True\n",
    "    )\n",
    "    \n",
    "    # Train quick models (fewer epochs)\n",
    "    fnn_temp = NeuralPredictor(\n",
    "        FeedForwardPredictor(WINDOW_SIZE * 2, [64, 32], 2), learning_rate=0.001\n",
    "    )\n",
    "    fnn_temp.train(X_tr, y_tr, epochs=30, verbose=False)\n",
    "    \n",
    "    lstm_temp = NeuralPredictor(\n",
    "        LSTMPredictor(2, 32, 2, 2), learning_rate=0.001\n",
    "    )\n",
    "    lstm_temp.train(X_tr, y_tr, epochs=30, verbose=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    fnn_pred = fnn_temp.predict(X_te)\n",
    "    lstm_pred = lstm_temp.predict(X_te)\n",
    "    \n",
    "    fnn_rmse = evaluate_prediction(y_te, fnn_pred)['rmse']\n",
    "    lstm_rmse = evaluate_prediction(y_te, lstm_pred)['rmse']\n",
    "    \n",
    "    noise_results['fnn'].append(fnn_rmse)\n",
    "    noise_results['lstm'].append(lstm_rmse)\n",
    "    \n",
    "    print(f\"  FNN RMSE:  {fnn_rmse:.6f}\")\n",
    "    print(f\"  LSTM RMSE: {lstm_rmse:.6f}\")\n",
    "\n",
    "# Plot noise sensitivity\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(noise_levels, noise_results['fnn'], 'bo-', linewidth=2, markersize=8, label='Feed-Forward')\n",
    "ax.plot(noise_levels, noise_results['lstm'], 'ro-', linewidth=2, markersize=8, label='LSTM')\n",
    "ax.set_xlabel('Noise Standard Deviation', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_title('Model Robustness to Measurement Noise', fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 12. Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **One-step prediction**: Both FNN and LSTM achieve good accuracy for one-step ahead prediction\n",
    "2. **Multi-step prediction**: Error grows exponentially with prediction horizon (chaotic dynamics)\n",
    "3. **LSTM vs FNN**: LSTM typically maintains better long-term prediction due to memory mechanisms\n",
    "4. **Noise robustness**: Models are reasonably robust to small amounts of measurement noise\n",
    "\n",
    "### Duffing Oscillator Characteristics:\n",
    "\n",
    "| Aspect | Periodic Regime ($\\gamma=0.2$) | Chaotic Regime ($\\gamma=0.37$) |\n",
    "|--------|--------------------------------|---------------------------------|\n",
    "| **Attractor Type** | Periodic orbit | Strange attractor |\n",
    "| **Predictability** | Long-term | Limited horizon |\n",
    "| **Error Growth** | Bounded | Exponential |\n",
    "| **Forcing Dependence** | Stable response | Sensitive to forcing |\n",
    "| **Neural Network Task** | Learn periodic pattern | Learn chaotic flow |\n",
    "\n",
    "### Comparison with Other Systems:\n",
    "\n",
    "| System | Dimension | Type | Predictability | Neural Network Challenge |\n",
    "|--------|-----------|------|----------------|-------------------------|\n",
    "| **Lorenz** | 3D | Autonomous chaos | Limited | Learn 3D strange attractor |\n",
    "| **Rössler** | 3D | Autonomous chaos | Limited | Learn spiral attractor |\n",
    "| **Van der Pol** | 2D | Limit cycle | Long-term | Learn periodic orbit |\n",
    "| **Duffing** | 2D | Forced chaos | Limited | Learn forced dynamics |\n",
    "\n",
    "### Insights:\n",
    "\n",
    "- **Forced dynamics**: The external forcing ($\\gamma\\cos(\\omega t)$) makes the Duffing system non-autonomous, adding complexity\n",
    "- **Bistability**: The double-well potential ($\\alpha < 0$) enables switching between wells, creating rich dynamics\n",
    "- **Route to chaos**: The system transitions from periodic to chaotic behavior as forcing amplitude increases\n",
    "- **Prediction limits**: Like other chaotic systems, long-term prediction is fundamentally limited by sensitivity to initial conditions\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- Structural vibrations and buckling dynamics\n",
    "- Energy harvesting from vibrations\n",
    "- Nonlinear optics and laser dynamics\n",
    "- Electronic circuits and oscillators\n",
    "- Mechanical systems with nonlinear restoring forces\n",
    "\n",
    "### Limitations:\n",
    "\n",
    "- Chaotic systems have limited predictability horizons due to sensitivity to initial conditions\n",
    "- Models learn patterns but cannot overcome fundamental Lyapunov divergence\n",
    "- External forcing parameters ($\\gamma$, $\\omega$) must be known or embedded in the training data\n",
    "- Longer prediction horizons would require different approaches (ensemble methods, data assimilation)\n",
    "\n",
    "### Future Work:\n",
    "\n",
    "- Test with different forcing amplitudes to study periodic and chaotic regimes\n",
    "- Implement physics-informed neural networks that encode the Duffing equation structure\n",
    "- Explore bifurcation diagrams using neural network predictions\n",
    "- Compare with traditional nonlinear dynamics methods (Poincaré sections, Lyapunov exponents)\n",
    "- Investigate ensemble prediction methods for uncertainty quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ Duffing oscillator analysis finished successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
